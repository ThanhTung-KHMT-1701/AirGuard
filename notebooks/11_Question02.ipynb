{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562a0781",
   "metadata": {},
   "source": [
    "# Thá»­ nghiá»‡m vÃ  Cáº£i tiáº¿n cho Co-Training\n",
    "\n",
    "**Má»¥c tiÃªu:**\n",
    "Notebook nÃ y thá»±c hiá»‡n quÃ¡ trÃ¬nh sweep (thá»­ nghiá»‡m) cÃ¡c tham sá»‘ vÃ  chiáº¿n lÆ°á»£c tÃ¡ch view khÃ¡c nhau cho thuáº­t toÃ¡n Co-Training nháº±m tÃ¬m ra cáº¥u hÃ¬nh tá»‘i Æ°u vÃ  cáº£i thiá»‡n hiá»‡u nÄƒng so vá»›i káº¿t quáº£ ban Ä‘áº§u.\n",
    "\n",
    "**CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**\n",
    "1.  Äá»‹nh nghÄ©a cÃ¡c bá»™ tham sá»‘ vÃ  chiáº¿n lÆ°á»£c tÃ¡ch view Ä‘á»ƒ thá»­ nghiá»‡m:\n",
    "    *   `TAU` (NgÆ°á»¡ng tá»± tin): `[0.9, 0.8]`\n",
    "    *   `MAX_NEW_PER_ITER` (Sá»‘ máº«u má»›i tá»‘i Ä‘a má»—i vÃ²ng): `[250, 500]`\n",
    "    *   **View Splitting Strategies**:\n",
    "        *   `default`: TÃ¡ch tá»± Ä‘á»™ng (sensor/lag vs. context/time).\n",
    "        *   `manual`: TÃ¡ch thá»§ cÃ´ng cÃ¡c feature thá»i tiáº¿t sang View 2.\n",
    "2.  Sá»­ dá»¥ng `papermill` Ä‘á»ƒ cháº¡y notebook `05_semi_co_training.ipynb` vá»›i 8 cáº¥u hÃ¬nh khÃ¡c nhau.\n",
    "3.  Tá»± Ä‘á»™ng lÆ°u káº¿t quáº£ vÃ o thÆ° má»¥c `data/processed/` vá»›i tiá»n tá»‘ `11_ID_*`.\n",
    "4.  Tá»•ng há»£p vÃ  trá»±c quan hÃ³a káº¿t quáº£ Ä‘á»ƒ so sÃ¡nh hiá»‡u nÄƒng vÃ  chá»n ra mÃ´ hÃ¬nh tá»‘t nháº¥t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830de740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -------- Cáº¥u hÃ¬nh thá»­ nghiá»‡m --------\n",
    "PROJECT_ROOT = Path(\".\").resolve().parent\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "KERNEL = \"KhaiPhaDuLieu\"\n",
    "\n",
    "# --- Tham sá»‘ Ä‘á»ƒ sweep ---\n",
    "TAU_LIST = [0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6]\n",
    "MAX_NEW_PER_ITER_LIST = [250, 500] # ThÃªm Ä‘iá»ƒm Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ Ä‘Æ°á»ng\n",
    "\n",
    "# --- Chiáº¿n lÆ°á»£c tÃ¡ch view ---\n",
    "# Äá»c danh sÃ¡ch features tá»« file Ä‘Ã£ táº¡o á»Ÿ notebook 03\n",
    "feature_list_path = PROJECT_ROOT / \"data\" / \"processed\" / \"03_feature_list.csv\"\n",
    "df_features = pd.read_csv(feature_list_path)\n",
    "all_features = df_features[\"feature\"].tolist()\n",
    "\n",
    "# 1. Manual split: View 2 chá»©a cÃ¡c Ä‘áº·c trÆ°ng thá»i tiáº¿t, View 1 chá»©a pháº§n cÃ²n láº¡i\n",
    "manual_view2_cols = [col for col in all_features if any(sub in col for sub in [\"wd\", \"temp\", \"pres\", \"humi\"])]\n",
    "manual_view1_cols = [col for col in all_features if col not in manual_view2_cols]\n",
    "\n",
    "# 2. PCA-based split: TÃ¡ch dá»±a trÃªn principal components\n",
    "print(\"TÃ­nh toÃ¡n PCA-based split...\")\n",
    "semi_dataset_path = PROJECT_ROOT / \"data\" / \"processed\" / \"02_dataset_for_semi.parquet\"\n",
    "df_semi = pd.read_parquet(semi_dataset_path)\n",
    "\n",
    "# Chá»‰ sá»­ dá»¥ng labeled data Ä‘á»ƒ tÃ­nh PCA\n",
    "df_labeled = df_semi[df_semi[\"is_labeled\"] == True].copy()\n",
    "\n",
    "# Lá»c chá»‰ cÃ¡c features numeric (loáº¡i bá» categorical nhÆ° 'wd', 'station')\n",
    "numeric_features = [col for col in all_features if col not in ['wd', 'station']]\n",
    "X_labeled = df_labeled[numeric_features].fillna(0)  # Fill NaN náº¿u cÃ³\n",
    "\n",
    "# Chuáº©n hÃ³a vÃ  tÃ­nh PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_labeled)\n",
    "\n",
    "# TÃ­nh PCA vá»›i sá»‘ components báº±ng sá»‘ features\n",
    "n_components = min(20, len(numeric_features))  # Giá»›i háº¡n sá»‘ PC Ä‘á»ƒ tÄƒng tá»‘c\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Láº¥y absolute loadings vÃ  phÃ¢n chia features\n",
    "# View 1: Features cÃ³ loading cao á»Ÿ cÃ¡c PC cháºµn (PC0, PC2, PC4,...)\n",
    "# View 2: Features cÃ³ loading cao á»Ÿ cÃ¡c PC láº» (PC1, PC3, PC5,...)\n",
    "loadings = np.abs(pca.components_)  # Shape: (n_components, n_features)\n",
    "\n",
    "even_pcs = loadings[0::2, :]  # PC0, PC2, PC4,...\n",
    "odd_pcs = loadings[1::2, :]   # PC1, PC3, PC5,...\n",
    "\n",
    "# TÃ­nh tá»•ng loading cho má»—i feature\n",
    "even_loadings = even_pcs.sum(axis=0)\n",
    "odd_loadings = odd_pcs.sum(axis=0)\n",
    "\n",
    "# PhÃ¢n chia features dá»±a trÃªn loading cao hÆ¡n\n",
    "pca_view1_cols = [numeric_features[i] for i in range(len(numeric_features)) if even_loadings[i] >= odd_loadings[i]]\n",
    "pca_view2_cols = [numeric_features[i] for i in range(len(numeric_features)) if even_loadings[i] < odd_loadings[i]]\n",
    "\n",
    "# ThÃªm categorical features vÃ o view1 (náº¿u cÃ³)\n",
    "categorical_features = [col for col in all_features if col in ['wd', 'station']]\n",
    "if categorical_features:\n",
    "    pca_view1_cols.extend(categorical_features)\n",
    "\n",
    "print(f\"PCA split: View1={len(pca_view1_cols)} features, View2={len(pca_view2_cols)} features\")\n",
    "\n",
    "VIEW_STRATEGIES = {\n",
    "    \"default\": {\n",
    "        \"VIEW1_COLS\": None,  # Äá»ƒ notebook 05 tá»± tÃ¡ch\n",
    "        \"VIEW2_COLS\": None,\n",
    "    },\n",
    "    \"manual_weather_split\": {\n",
    "        \"VIEW1_COLS\": manual_view1_cols,\n",
    "        \"VIEW2_COLS\": manual_view2_cols,\n",
    "    },\n",
    "    \"pca_based_split\": {\n",
    "        \"VIEW1_COLS\": pca_view1_cols,\n",
    "        \"VIEW2_COLS\": pca_view2_cols,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a6df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Cháº¡y thá»­ nghiá»‡m vá»›i Papermill --------\n",
    "# Táº¡o thÆ° má»¥c runs náº¿u chÆ°a cÃ³\n",
    "runs_dir = Path(\"runs\")\n",
    "runs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "experiment_id = 1\n",
    "config_list = []\n",
    "\n",
    "# Táº¡o danh sÃ¡ch táº¥t cáº£ cÃ¡c cáº¥u hÃ¬nh\n",
    "for view_name, view_cols in VIEW_STRATEGIES.items():\n",
    "    for tau in TAU_LIST:\n",
    "        for max_new in MAX_NEW_PER_ITER_LIST:\n",
    "            config_list.append({\n",
    "                \"view_name\": view_name,\n",
    "                \"tau\": tau,\n",
    "                \"max_new_per_iter\": max_new,\n",
    "                \"view1_cols\": view_cols[\"VIEW1_COLS\"],\n",
    "                \"view2_cols\": view_cols[\"VIEW2_COLS\"],\n",
    "            })\n",
    "\n",
    "# Cháº¡y láº·p qua cÃ¡c cáº¥u hÃ¬nh\n",
    "total_experiments = len(config_list)\n",
    "for config in config_list:\n",
    "    print(f\"--- Thá»­ nghiá»‡m {experiment_id}/{total_experiments}: \"\n",
    "          f\"View='{config['view_name']}', TAU={config['tau']}, MAX_NEW={config['max_new_per_iter']} ---\")\n",
    "\n",
    "    metrics_path = f\"data/processed/11_{experiment_id:02d}_metrics_co_training.json\"\n",
    "    output_notebook_path = f\"runs/11_{experiment_id:02d}_co_training_run.ipynb\"\n",
    "\n",
    "    try:\n",
    "        pm.execute_notebook(\n",
    "            input_path=\"05_semi_co_training.ipynb\",\n",
    "            output_path=output_notebook_path,\n",
    "            parameters=dict(\n",
    "                SEMI_DATASET_PATH=\"data/processed/02_dataset_for_semi.parquet\",\n",
    "                CUTOFF=\"2017-01-01\",\n",
    "                TAU=config[\"tau\"],\n",
    "                MAX_ITER=5, # Giá»¯ nguyÃªn MAX_ITER\n",
    "                MAX_NEW_PER_ITER=config[\"max_new_per_iter\"],\n",
    "                MIN_NEW_PER_ITER=200,\n",
    "                VAL_FRAC=0.1,\n",
    "                RANDOM_STATE=42,\n",
    "                METRICS_PATH=metrics_path,\n",
    "                # KhÃ´ng cáº§n lÆ°u sample predictions/alerts cho sweep\n",
    "                PRED_SAMPLE_PATH=None, \n",
    "                ALERTS_SAMPLE_PATH=None,\n",
    "                ALERT_FROM_CLASS=\"Unhealthy\",\n",
    "                VIEW1_COLS=config[\"view1_cols\"],\n",
    "                VIEW2_COLS=config[\"view2_cols\"],\n",
    "            ),\n",
    "            kernel_name=KERNEL,\n",
    "            cwd=str(PROJECT_ROOT)\n",
    "        )\n",
    "        print(f\"âœ… HoÃ n thÃ nh vÃ  lÆ°u káº¿t quáº£ táº¡i: {metrics_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i khi cháº¡y thá»­ nghiá»‡m {experiment_id}: {e}\")\n",
    "    \n",
    "    experiment_id += 1\n",
    "\n",
    "print(\"\\nðŸŽ‰ Táº¥t cáº£ thá»­ nghiá»‡m Co-Training Ä‘Ã£ hoÃ n táº¥t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f0747",
   "metadata": {},
   "source": [
    "# Tá»•ng há»£p vÃ  PhÃ¢n tÃ­ch káº¿t quáº£\n",
    "\n",
    "ChÃºng ta sáº½ Ä‘á»c táº¥t cáº£ cÃ¡c file metrics Ä‘Ã£ Ä‘Æ°á»£c táº¡o ra, tá»•ng há»£p chÃºng vÃ o má»™t DataFrame vÃ  hiá»ƒn thá»‹ káº¿t quáº£ Ä‘á»ƒ so sÃ¡nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82241ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# -------- Cáº¥u hÃ¬nh --------\n",
    "PROJECT_ROOT = Path(\".\").resolve().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "TOTAL_EXPERIMENTS = len(VIEW_STRATEGIES) * len(TAU_LIST) * len(MAX_NEW_PER_ITER_LIST)  # 3 strategies Ã— 2 TAU Ã— 2 MAX_NEW\n",
    "\n",
    "# -------- Äá»c vÃ  tá»•ng há»£p káº¿t quáº£ --------\n",
    "results = []\n",
    "for i in range(1, TOTAL_EXPERIMENTS + 1):\n",
    "    metrics_path = DATA_DIR / f\"11_{i:02d}_metrics_co_training.json\"\n",
    "    \n",
    "    if metrics_path.exists():\n",
    "        with open(metrics_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            # TrÃ­ch xuáº¥t thÃ´ng tin\n",
    "            config = data.get(\"ct_cfg\", {})\n",
    "            test_metrics = data.get(\"test_metrics\", {})\n",
    "            \n",
    "            # XÃ¡c Ä‘á»‹nh view strategy dá»±a trÃªn sá»‘ lÆ°á»£ng cá»™t\n",
    "            view_strategy = \"default\"\n",
    "            if config.get(\"view1_cols_count\") is not None:\n",
    "                 if config.get(\"view1_cols_count\") == len(manual_view1_cols):\n",
    "                     view_strategy = \"manual_weather_split\"\n",
    "                 elif config.get(\"view1_cols_count\") == len(pca_view1_cols):\n",
    "                     view_strategy = \"pca_based_split\"\n",
    "\n",
    "            results.append({\n",
    "                \"experiment_id\": i,\n",
    "                \"view_strategy\": view_strategy,\n",
    "                \"tau\": config.get(\"tau\"),\n",
    "                \"max_new_per_iter\": config.get(\"max_new_per_iter\"),\n",
    "                \"f1_macro\": test_metrics.get(\"f1_macro\"),\n",
    "                \"accuracy\": test_metrics.get(\"accuracy\"),\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y file {metrics_path}\")\n",
    "\n",
    "# Táº¡o DataFrame\n",
    "if results:\n",
    "    df_results_co = pd.DataFrame(results)\n",
    "    df_results_co[\"label\"] = (\n",
    "        df_results_co[\"view_strategy\"]\n",
    "        + \"\\nTAU=\" + df_results_co[\"tau\"].astype(str)\n",
    "        + \", MAX_NEW=\" + df_results_co[\"max_new_per_iter\"].astype(str)\n",
    "    )\n",
    "    \n",
    "    print(\"Báº£ng tá»•ng há»£p káº¿t quáº£ thá»­ nghiá»‡m Co-Training:\")\n",
    "    display(df_results_co.sort_values(\"f1_macro\", ascending=False))\n",
    "\n",
    "else:    print(\"KhÃ´ng cÃ³ káº¿t quáº£ nÃ o Ä‘á»ƒ hiá»ƒn thá»‹.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1873dd5",
   "metadata": {},
   "source": [
    "# Trá»±c quan hÃ³a káº¿t quáº£\n",
    "\n",
    "Biá»ƒu Ä‘á»“ cá»™t sáº½ so sÃ¡nh trá»±c quan chá»‰ sá»‘ F1-macro cá»§a táº¥t cáº£ 8 cáº¥u hÃ¬nh Co-Training, giÃºp ta nhanh chÃ³ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c sá»± káº¿t há»£p tham sá»‘ nÃ o lÃ  hiá»‡u quáº£ nháº¥t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------- Cáº¥u hÃ¬nh biá»ƒu Ä‘á»“ --------\n",
    "IMAGES_DIR = PROJECT_ROOT / \"images\"\n",
    "IMAGES_DIR.mkdir(exist_ok=True)\n",
    "FONT_CONFIG = {'fontname': 'Arial', 'fontsize': 11}\n",
    "PALETTE = {\n",
    "    \"default\": \"#1F62FF\",              # Xanh nÆ°á»›c biá»ƒn\n",
    "    \"manual_weather_split\": \"#FF9A1F\", # Cam\n",
    "    \"pca_based_split\": \"#1FFF2A\"       # Xanh lÃ¡ cÃ¢y\n",
    "}\n",
    "\n",
    "# -------- Biá»ƒu Ä‘á»“ so sÃ¡nh F1-macro (TÃ¡ch riÃªng tá»«ng View Strategy) --------\n",
    "if 'df_results_co' in locals() and not df_results_co.empty:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    # Chuyá»ƒn Ä‘á»•i TAU thÃ nh category Ä‘á»ƒ seaborn xá»­ lÃ½ hue tá»‘t hÆ¡n\n",
    "    if not pd.api.types.is_categorical_dtype(df_results_co['tau']):\n",
    "        df_results_co['tau'] = df_results_co['tau'].astype('category')\n",
    "\n",
    "    # Láº·p qua tá»«ng view_strategy Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ riÃªng\n",
    "    for i, view_strategy in enumerate(df_results_co['view_strategy'].unique()):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        \n",
    "        # Lá»c dá»¯ liá»‡u cho view_strategy hiá»‡n táº¡i\n",
    "        strategy_data = df_results_co[df_results_co['view_strategy'] == view_strategy]\n",
    "        \n",
    "        # Váº½ biá»ƒu Ä‘á»“ cá»™t\n",
    "        sns.barplot(\n",
    "            data=strategy_data,\n",
    "            x=\"max_new_per_iter\",\n",
    "            y=\"f1_macro\",\n",
    "            hue=\"tau\",\n",
    "            palette=['#1F62FF', '#FF9A1F'], # MÃ u cho TAU\n",
    "            ax=ax,\n",
    "            errorbar=None # Táº¯t Ä‘Æ°á»ng káº» lá»—i (error bar)\n",
    "        )\n",
    "        \n",
    "        # ThÃªm text giÃ¡ trá»‹ trÃªn cá»™t\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.4f', fontsize=10, padding=3)\n",
    "            \n",
    "        # Äá»‹nh dáº¡ng\n",
    "        ax.set_xlabel(\"MAX_NEW_PER_ITER\", **FONT_CONFIG)\n",
    "        ax.set_ylabel(\"F1-macro Score\", **FONT_CONFIG)\n",
    "        ax.set_ylim(0, df_results_co['f1_macro'].max() * 1.15)\n",
    "        \n",
    "        title_font_config = FONT_CONFIG.copy()\n",
    "        title_font_config['fontsize'] = 14\n",
    "        ax.set_title(f\"Co-Training Performance: View Strategy = '{view_strategy}'\", **title_font_config)\n",
    "        \n",
    "        ax.legend(title='TAU', prop={'family': 'Arial', 'size': 11})\n",
    "        \n",
    "        plt.tight_layout(pad=1.5)\n",
    "        \n",
    "        # LÆ°u biá»ƒu Ä‘á»“\n",
    "        save_path = IMAGES_DIR / f\"11_{i+1:02d}_co_training_{view_strategy}.png\"\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"Biá»ƒu Ä‘á»“ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {save_path}\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86359da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Biá»ƒu Ä‘á»“ cá»™t: So sÃ¡nh 3 View Strategies vá»›i cÃ¡c giÃ¡ trá»‹ TAU khÃ¡c nhau --------\n",
    "if 'df_results_co' in locals() and not df_results_co.empty:\n",
    "    \n",
    "    # Sá»­ dá»¥ng catplot Ä‘á»ƒ táº¡o biá»ƒu Ä‘á»“ cá»™t vá»›i cÃ¡c subplot cho má»—i giÃ¡ trá»‹ TAU\n",
    "    g = sns.catplot(\n",
    "        data=df_results_co,\n",
    "        x=\"max_new_per_iter\",\n",
    "        y=\"f1_macro\",\n",
    "        hue=\"view_strategy\",\n",
    "        col=\"tau\",  # Táº¡o subplot cho má»—i giÃ¡ trá»‹ TAU\n",
    "        kind=\"bar\",\n",
    "        palette=PALETTE,\n",
    "        errorbar=None,\n",
    "        height=6, # Chiá»u cao má»—i subplot\n",
    "        aspect=1.2 # Tá»· lá»‡ chiá»u rá»™ng/chiá»u cao\n",
    "    )\n",
    "\n",
    "    # ThÃªm text giÃ¡ trá»‹ trÃªn má»—i cá»™t\n",
    "    for ax in g.axes.flat:\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.4f', fontsize=9, padding=3, **{'fontname': 'Arial'})\n",
    "\n",
    "    # --- Cáº¥u hÃ¬nh biá»ƒu Ä‘á»“ ---\n",
    "    g.set_axis_labels(\"MAX_NEW_PER_ITER (Maximum New Samples per Iteration)\", \"F1-macro Score\")\n",
    "    g.set_titles(\"TAU = {col_name}\")\n",
    "    g.fig.suptitle('Comparison of View Strategies for Co-Training across different TAU values', fontsize=16, fontname='Arial', y=1.03)\n",
    "    \n",
    "    # Äiá»u chá»‰nh legend\n",
    "    sns.move_legend(g, \"upper right\", bbox_to_anchor=(.95, .95), title='View Strategy')\n",
    "\n",
    "    # Äáº·t giá»›i háº¡n trá»¥c y Ä‘á»ƒ dá»… so sÃ¡nh hÆ¡n\n",
    "    y_max = df_results_co['f1_macro'].max()\n",
    "    for ax in g.axes.flat:\n",
    "        ax.set_ylim(0, y_max * 1.15)\n",
    "\n",
    "    # Äiá»u chá»‰nh layout\n",
    "    plt.tight_layout(pad=2.0, rect=[0, 0, 1, 0.96]) # Äiá»u chá»‰nh Ä‘á»ƒ title khÃ´ng bá»‹ Ä‘Ã¨\n",
    "    \n",
    "    # LÆ°u biá»ƒu Ä‘á»“\n",
    "    save_path = IMAGES_DIR / \"11_04_co_training_strategy_comparison_by_tau.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Biá»ƒu Ä‘á»“ so sÃ¡nh chiáº¿n lÆ°á»£c (theo TAU) Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {save_path}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KhaiPhaDuLieu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
